{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cadenas en LangChain\n",
    "\n",
    "Las cadenas en LangChain permiten crear flujos de trabajo, donde se conectan distintos \"bloques\" para construir sistemas con modelos de lenguaje más complejos.\n",
    "\n",
    "Por ejemplo, si necesitas un sistema que conecte múltiples entradas y salidas entre LLMs, las cadenas te permiten gestionar qué modelo genera qué información, con qué prompt, y cómo la salida de un modelo puede usarse como entrada de otro.\n",
    "Cadenas más usadas\n",
    "\n",
    "LangChain incluye diversas cadenas integradas, pero estas son las más comunes para desarrollar sistemas complejos:\n",
    "\n",
    "1. LLMChain\n",
    "2. SequentialChain\n",
    "3. Math/Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. LLMChain\n",
    "\n",
    "La LLMChain es una de las cadenas más utilizadas. Facilita la interacción con los modelos al unir dos elementos clave:\n",
    "\n",
    "- Un modelo LLM (como OpenAI, LLama, Cohere, etc.)\n",
    ". Un template de prompt.\n",
    "\n",
    "\n",
    "En este ejemplo, el modelo actúa como un asistente para estudiantes y devuelve una lista de tres puntos clave sobre un tema académico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain, OpenAI, PromptTemplate\n",
    "import config  # Archivo con la API key\n",
    "\n",
    "# Template modificado para un asistente académico\n",
    "prompt = '''Eres un asistente para estudiantes que explica {tema} \n",
    "            enumerando 3 puntos clave de forma clara y precisa.\n",
    "            Solo menciona los tres puntos.'''\n",
    "template = PromptTemplate.from_template(prompt)\n",
    "\n",
    "# Configuración del modelo usando API key desde config.py\n",
    "llm = OpenAI(openai_api_key=config.OPENAI_API_KEY)\n",
    "\n",
    "# Creación de la cadena LLM\n",
    "cadena_LLM = LLMChain(llm=llm, prompt=template)\n",
    "\n",
    "# Predicción con la cadena\n",
    "output = cadena_LLM.predict(tema=\"la fotosíntesis\") #Se le pasa mediante el .predict (veremos en secuencia de cadenas que se pasa como diccionario)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SequentialChain en LangChain\n",
    "\n",
    "Para muchos casos de uso, enviar un texto para procesarlo no es suficiente. A menudo, se requiere una secuencia de procesos que se ejecuten en orden, donde la salida de un modelo funcione como entrada para otro. LangChain ofrece dos opciones principales para esto:\n",
    "\n",
    "- SimpleSequentialChain: Más básica, maneja un solo flujo lineal de entrada/salida.\n",
    "- SequentialChain: Más flexible, permite manejar múltiples entradas y salidas.\n",
    "\n",
    "En este ejemplo, usaremos SequentialChain, ya que ofrece mayor flexibilidad y la capacidad de recibir múltiples variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain, PromptTemplate\n",
    "import config  # API key desde un archivo config.py\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "# Prompt para generar una lista de conceptos clave\n",
    "prompt_lista = '''Eres un asistente para estudiantes que explica {tema} \n",
    "                  enumerando 3 puntos clave de forma clara y precisa.\n",
    "                  Solo menciona los tres puntos.'''\n",
    "template_lista = PromptTemplate.from_template(prompt_lista)\n",
    "\n",
    "# Creación de la primera cadena\n",
    "llm = OpenAI(openai_api_key=config.API_KEY)\n",
    "cadena_lista = LLMChain(llm=llm, prompt=template_lista, output_key=\"lista_conceptos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt para decidir por dónde iniciar el aprendizaje\n",
    "prompt_inicio = '''Eres un asistente académico que analiza una lista de conceptos \n",
    "                   clave y decide cuál es mejor aprender primero.\n",
    "                   Los conceptos son: {lista_conceptos}. Indica solo uno.'''\n",
    "template_inicio = PromptTemplate.from_template(prompt_inicio)\n",
    "\n",
    "# Creación de la segunda cadena\n",
    "cadena_inicio = LLMChain(llm=llm, prompt=template_inicio, output_key=\"donde_iniciar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encadenamiento de procesos\n",
    "cadenas = SequentialChain(\n",
    "    chains=[cadena_lista, cadena_inicio],\n",
    "    input_variables=[\"tema\"],  # Variables de entrada iniciales\n",
    "    output_variables=[\"lista_conceptos\", \"donde_iniciar\"],  # Variables de salida finales\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Ejecución con un tema de prueba\n",
    "resultado = cadenas({\"tema\": \"la fotosíntesis\"}) #se llama directamente a la función y no se usa .predict, se le pasa un diccionario\n",
    "print(resultado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SimpleSequentialChain\n",
    "\n",
    "Para un flujo más básico, se puede usar SimpleSequentialChain, aunque no permite múltiples entradas ni salidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "# Encadenamiento simple\n",
    "cadena_simple = SimpleSequentialChain(\n",
    "    chains=[cadena_lista, cadena_inicio], \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Ejecución con un tema diferente\n",
    "resultado_simple = cadena_simple.run(\"Inteligencia Artificial\")\n",
    "print(resultado_simple)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Otros Ejemplos de Cadenas\n",
    "\n",
    "LangChain ofrece herramientas específicas como MathChain y TransformChain para cubrir necesidades comunes. Vamos a explorar estos ejemplos:\n",
    "\n",
    "#### MathChain\n",
    "\n",
    "- Diseñada para realizar cálculos matemáticos.\n",
    "- Integra LLMs para interpretar y resolver problemas matemáticos.\n",
    "- Utiliza herramientas como Python o entornos simbólicos para garantizar la precisión en los cálculos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMMathChain\n",
    "\n",
    "# Crear la cadena para cálculos matemáticos\n",
    "cadena_mate = LLMMathChain(llm=llm, verbose=True)\n",
    "\n",
    "# Realizar un cálculo\n",
    "resultado = cadena_mate.run(\"Cuánto es 432 * 12 - 32 + 32?\")\n",
    "print(resultado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TransformChain\n",
    "\n",
    "- Permite realizar transformaciones personalizadas en los datos.\n",
    "- Ideal para manipular texto, convertir formatos o realizar preprocesamientos personalizados.\n",
    "- Utilizas una función Python personalizada para definir la transformación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import TransformChain\n",
    "\n",
    "# Definir una función para eliminar saltos de línea\n",
    "def eliminar_brincos(input):\n",
    "    \"\"\"Elimina los brincos de línea de un texto.\"\"\"\n",
    "    texto = input[\"texto\"]\n",
    "    return {\"texto_limpio\": texto.replace(\"\\n\", \" \")}\n",
    "\n",
    "# Crear la cadena de transformación\n",
    "cadena_transformacion = TransformChain(\n",
    "    input_variables=[\"texto\"],\n",
    "    output_variables=[\"texto_limpio\"],\n",
    "    transform=eliminar_brincos\n",
    ")\n",
    "\n",
    "# Definir un texto con saltos de línea\n",
    "prompt = '''\\nEste es un texto \\ncon brincos de\\n línea.\\n\\n'''\n",
    "\n",
    "# Ejecutar la transformación\n",
    "resultado = cadena_transformacion.run({\"texto\": prompt})\n",
    "print(resultado)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
